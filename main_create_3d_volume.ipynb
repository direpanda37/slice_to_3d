{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "  [*Ronneberger et al, 2015, U-Net: Convolutional Networks for Biomedical Image Segmentation*](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
    "  \n",
    "  [*Machireddy et al, 2021, Robust Segmentation of Cellular Ultrastructure on Sparsely Labeled 3D Electron Microscopy Images using Deep Learning*](https://www.biorxiv.org/content/10.1101/2021.05.27.446019v1.full)\n",
    "\n",
    "# objectives\n",
    "- PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT \n",
    "- Streamline the use of volumetric electron microscopy (vEM) cell images to create a 3D model for the purpose of gaining *\"deeper understanding of the cellular and subcellular organization of tumor cells and their interactions with the tumor microenvironment (to) shed light on how cancer evolves and guide effective therapy choices.\"*\n",
    "- Provide models and tools for researchers to tailor to meet their needs\n",
    "- Support an interative training and test model, allowing researchers to start/stop and adjust without losing existing progress\n",
    "- Take advantage of hardware acceleration\n",
    "\n",
    "# workflow\n",
    "\n",
    "Using electron microscopy (vEM) cell images to create a 3D model is as follows:\n",
    "- Take a stack of vEM slices of tissue and \n",
    "  - pre-process the images as needed and scale them to 512x512\n",
    "- If training the model\n",
    "  - optionally apply data augmentation to increase the training dataset and push the images through the the training process\n",
    "  - optionally, load a pretrained model and use additional training to fine-tune\n",
    "  - train the model, saving checkpoints periodically and reporting progress as the model is training\n",
    "  - save the final model parameters/weights\n",
    "- If segmenting images with an existing model\n",
    "  - create the model and load pretrained weights into the model\n",
    "  - convert each image into a segmented image using a pretrained UNet model\n",
    "  - save the segmented images as PNG files\n",
    "- Load the stack of images as a 3D [NumPy](https://numpy.org/doc/stable/) array using [imageio.imread()](https://imageio.readthedocs.io/en/v2.16.1/_autosummary/imageio.imread.html).\n",
    "- Use the [marching cubes algorithm](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.marching_cubes) from the scikit-image submodule `skimage.measure` to convert the voxels of interest to a list of faces defined by vertices on the surface of the volume.\n",
    "- Use [numpy-stl](https://numpy-stl.readthedocs.io/en/latest/) to create an `stl.Mesh` object from the list of faces and vertices (as done in [this example](https://numpy-stl.readthedocs.io/en/latest/usage.html#creating-mesh-objects-from-a-list-of-vertices-and-faces)) then save the mesh with `stl.Mesh.save()`.\n",
    "- As a bonus, you can use the Python package for the [Open3D](http://www.open3d.org/docs/release/) library to open & view multiple STL files (not included here)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies\n",
    "\n",
    "model and data use TensorFlow+Keras >= 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from stl import Mesh\n",
    "import skimage.measure\n",
    "import os\n",
    "import glob\n",
    "import random as rand\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knobs and levers\n",
    "\n",
    "edit to match your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of training and test data\n",
    "data_dir = \"data/membrane/\"\n",
    "data_train_dir = data_dir+\"train\"\n",
    "data_test_dir = data_dir+\"test\"\n",
    "\n",
    "# save/load model weights\n",
    "model_weights_file = 'unet_membrane.hdf5'\n",
    "\n",
    "# slice stack sythesizer randomly grabs one image from this match in data_test_dir\n",
    "synth_image_stack_wildcard = \"*predict*\"\n",
    "\n",
    "# directory and file name for eventual 3d model\n",
    "stl_path = data_dir+\"3d/\"\n",
    "stl_file = stl_path+\"cube.stl\"\n",
    "\n",
    "# verbose?\n",
    "chatty_mode = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "### train new model\n",
    "\n",
    "TAKES MANY HOURS - SKIP IF USING PRETRAINED MODEL!\n",
    "\n",
    "augments training data, creates the zeroed model, and trains it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model():\n",
    "    data_gen_args = dict(rotation_range=0.2,\n",
    "                        width_shift_range=0.05,\n",
    "                        height_shift_range=0.05,\n",
    "                        shear_range=0.05,\n",
    "                        zoom_range=0.05,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='nearest')\n",
    "\n",
    "    # Load training data generator\n",
    "    train_data_gen = trainGenerator(\n",
    "        2, data_train_dir, 'image', 'label', data_gen_args, save_to_dir=None)\n",
    "\n",
    "    # Build the UNet model\n",
    "    model = unet_model(print_summary=chatty_mode)\n",
    "\n",
    "    # Fit the model using the training data generator - will save checkpoints\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        model_weights_file, monitor='loss', verbose=1 if chatty_mode else 0, save_best_only=True)\n",
    "    model.fit(train_data_gen, steps_per_epoch=2000,\n",
    "            epochs=5, callbacks=[model_checkpoint])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = train_new_model()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre-trained model\n",
    "\n",
    "OPTIONALLY SKIP IF JUST RAN TRAINING PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(model_weights_file, print_summary=chatty_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model and save segmented results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes test images are in given directory and have file names <prefix>0.png, <prefix>1.png, ...\n",
    "testGene = testGenerator(data_test_dir)\n",
    "results = model.predict_generator(testGene,30,verbose=1 if chatty_mode else 0)\n",
    "\n",
    "# saves segmented images to  directory with \"_predict\" appeneded i.e. 0_predict.png, ...\n",
    "saveResult(data_test_dir,results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D model\n",
    "\n",
    "### PNGs -> numpy voxel\n",
    "\n",
    "stack segmented images into 3D numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_slice_stack(dup_count=5, print_summary=False):\n",
    "    \n",
    "    # randomly select a segmented image\n",
    "    matching_files = glob.glob(os.path.join(data_test_dir, synth_image_stack_wildcard))\n",
    "    assert len(matching_files) != 0, data_test_dir+synth_image_stack_wildcard+\": found no files\"\n",
    "    random_file = matching_files[rand.randint(0, len(matching_files))]\n",
    "    assert os.path.isfile(random_file), \"{0} is not a file\".format(random_file)\n",
    "\n",
    "    # Stack PNG multiple times to create sythesized 3D slice stack\n",
    "    img = imageio.v2.imread(random_file)\n",
    "    image_stack = np.stack([img for i in range(dup_count)])\n",
    "\n",
    "    z_spacing = 10.0  # 5-10 works fine\n",
    "\n",
    "    if (print_summary):\n",
    "        print(\"Stacking {0} -> {1} spacing {2} to synthesize slice stack\".format(\n",
    "        random_file, image_stack.shape, z_spacing))\n",
    "    \n",
    "    # Return list of 2D arrays to a 3D NumPy array and a resonable z_spacing for stacked image\n",
    "    return image_stack, z_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stack, z_spacing = synth_slice_stack(print_summary=chatty_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voxels -> vertices + faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the voxels of interest to a list of faces defined by vertices on the surface of the volume\n",
    "verts, faces, _, _ = skimage.measure.marching_cubes(image_stack, \n",
    "                                                               level=None, \n",
    "                                                               spacing=(z_spacing, 1.0, 1.0),\n",
    "                                                               gradient_direction='descent', \n",
    "                                                               step_size=1, \n",
    "                                                               allow_degenerate=True, \n",
    "                                                               method='lewiner', \n",
    "                                                               mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of faceted data of the volume discovered by marching_cubes()\n",
    "print(\"Slice stack verts={0} faces={1}\".format(verts.shape, faces.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertices + faces -> 3D mesh -> STL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an stl.Mesh object from the list of faces and vertices\n",
    "cube = Mesh(np.zeros(faces.shape[0], dtype=Mesh.dtype))\n",
    "for i,f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        cube.vectors[i][j] = verts[f[j],:]\n",
    "\n",
    "# Save mesh as STL file that can be natively viewed on MacOS, Windows, Linux and can be easily 3D printed\n",
    "if not os.path.exists(stl_path):\n",
    "    os.makedirs(stl_path)\n",
    "cube.save(stl_file)\n",
    "print(\"3D model generated to {0}\".format(stl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
