{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "  [*Ronneberger et al, 2015, U-Net: Convolutional Networks for Biomedical Image Segmentation*](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
    "  \n",
    "  [*Machireddy et al, 2021, Robust Segmentation of Cellular Ultrastructure on Sparsely Labeled 3D Electron Microscopy Images using Deep Learning*](https://www.biorxiv.org/content/10.1101/2021.05.27.446019v1.full)\n",
    "\n",
    "# objectives\n",
    "- PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT \n",
    "- Streamline the use of volumetric electron microscopy (vEM) cell images to create a 3D model for the purpose of gaining *\"deeper understanding of the cellular and subcellular organization of tumor cells and their interactions with the tumor microenvironment (to) shed light on how cancer evolves and guide effective therapy choices.\"*\n",
    "- Provide models and tools for researchers to tailor to meet their needs\n",
    "- Support an interative training and test model, allowing researchers to start/stop and adjust without losing existing progress\n",
    "- Take advantage of hardware acceleration\n",
    "\n",
    "# workflow\n",
    "\n",
    "Using electron microscopy (vEM) cell images to create a 3D model is as follows:\n",
    "- Take a stack of vEM slices of tissue and \n",
    "  - pre-process the images as needed and scale them to 512x512\n",
    "- If training the model\n",
    "  - optionally apply data augmentation to increase the training dataset and push the images through the the training process\n",
    "  - optionally, load a pretrained model and use additional training to fine-tune\n",
    "  - train the model, saving checkpoints periodically and reporting progress as the model is training\n",
    "  - save the final model parameters/weights\n",
    "- If segmenting images with an existing model\n",
    "  - create the model and load pretrained weights into the model\n",
    "  - convert each image into a segmented image using a pretrained UNet model\n",
    "  - save the segmented images as PNG files\n",
    "- Load the stack of images as a 3D [NumPy](https://numpy.org/doc/stable/) array using [imageio.imread()](https://imageio.readthedocs.io/en/v2.16.1/_autosummary/imageio.imread.html).\n",
    "- Use the [marching cubes algorithm](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.marching_cubes) from the scikit-image submodule `skimage.measure` to convert the voxels of interest to a list of faces defined by vertices on the surface of the volume.\n",
    "- Use [numpy-stl](https://numpy-stl.readthedocs.io/en/latest/) to create an `stl.Mesh` object from the list of faces and vertices (as done in [this example](https://numpy-stl.readthedocs.io/en/latest/usage.html#creating-mesh-objects-from-a-list-of-vertices-and-faces)) then save the mesh with `stl.Mesh.save()`.\n",
    "- As a bonus, you can use the Python package for the [Open3D](http://www.open3d.org/docs/release/) library to open & view multiple STL files (not included here)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies\n",
    "\n",
    "model and data use TensorFlow+Keras >= 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from stl import Mesh\n",
    "import skimage.measure\n",
    "import os\n",
    "import glob\n",
    "import random as rand\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knobs and levers\n",
    "\n",
    "edit to match your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of training and test data\n",
    "data_dir = \"data/membrane/\"\n",
    "data_train_dir = data_dir+\"train\"\n",
    "data_test_dir = data_dir+\"test\"\n",
    "\n",
    "# save/load model weights\n",
    "model_weights_file = 'unet_membrane.hdf5'\n",
    "\n",
    "# slice stack sythesizer randomly grabs one image from this match in data_test_dir\n",
    "synth_image_stack_wildcard = \"*predict*\"\n",
    "\n",
    "# directory and file name for eventual 3d model\n",
    "stl_path = data_dir+\"3d/\"\n",
    "stl_file = stl_path+\"cube.stl\"\n",
    "\n",
    "# verbose?\n",
    "chatty_mode = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "### train new model\n",
    "\n",
    "TAKES MANY HOURS - SKIP IF USING PRETRAINED MODEL!\n",
    "\n",
    "augments training data, creates the zeroed model, and trains it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model():\n",
    "    data_gen_args = dict(rotation_range=0.2,\n",
    "                        width_shift_range=0.05,\n",
    "                        height_shift_range=0.05,\n",
    "                        shear_range=0.05,\n",
    "                        zoom_range=0.05,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='nearest')\n",
    "\n",
    "    # Load training data generator\n",
    "    train_data_gen = trainGenerator(\n",
    "        2, data_train_dir, 'image', 'label', data_gen_args, save_to_dir=None)\n",
    "\n",
    "    # Build the UNet model\n",
    "    model = unet_model(print_summary=chatty_mode)\n",
    "\n",
    "    # Fit the model using the training data generator - will save checkpoints\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        model_weights_file, monitor='loss', verbose=1 if chatty_mode else 0, save_best_only=True)\n",
    "    model.fit(train_data_gen, steps_per_epoch=2000,\n",
    "            epochs=5, callbacks=[model_checkpoint])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = train_new_model()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre-trained model\n",
    "\n",
    "OPTIONALLY SKIP IF JUST RAN TRAINING PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 32, 32, 512)          0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['dropout[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 16, 16, 1024)         0         ['conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['dropout_1[0][0]']           \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 512)          2097664   ['up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 1024)         0         ['dropout[0][0]',             \n",
      "                                                                     'conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 512)          4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 512)          2359808   ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['conv2d_12[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 256)          524544    ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 512)          0         ['conv2d_5[0][0]',            \n",
      " )                                                                   'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 256)          1179904   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 256)          590080    ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['conv2d_15[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 128)        131200    ['up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 256)        0         ['conv2d_3[0][0]',            \n",
      " )                                                                   'conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 128)        147584    ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['conv2d_18[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 256, 256, 64)         32832     ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 256, 256, 2)          1154      ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 256, 256, 1)          3         ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31031685 (118.38 MB)\n",
      "Trainable params: 31031685 (118.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet_model(model_weights_file, print_summary=chatty_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model and save segmented results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes test images are in given directory and have file names <prefix>0.png, <prefix>1.png, ...\n",
    "testGene = testGenerator(data_test_dir, data_test_prefix)\n",
    "results = model.predict_generator(testGene,30,verbose=1 if chatty_mode else 0)\n",
    "\n",
    "# saves segmented images to  directory with \"_predict\" appeneded i.e. 0_predict.png, ...\n",
    "saveResult(data_test_dir,results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D model\n",
    "\n",
    "### PNGs -> numpy voxel\n",
    "\n",
    "stack segmented images into 3D numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_slice_stack(dup_count=5):\n",
    "    # Find pre-segmented files that match the wildcard pattern\n",
    "    matching_files = glob.glob(os.path.join(data_test_dir, synth_image_stack_wildcard))\n",
    "    assert len(matching_files) != 0, data_test_dir+synth_image_stack_wildcard+\": found no files\"\n",
    "    random_file = matching_files[rand.randint(0, len(matching_files))]\n",
    "    assert os.path.isfile(random_file), \"{0} is not a file\".format(random_file)\n",
    "\n",
    "    # print the file\n",
    "    print(random_file)\n",
    "\n",
    "    # Stack one multiple times to crease sythesized 3D slice stack\n",
    "    img = imageio.v2.imread(random_file)\n",
    "    image_list = [img for i in range(dup_count)]\n",
    "\n",
    "    # Return list of 2D arrays to a 3D NumPy array and a resonable z_spacing for stacked image\n",
    "    z_spacing = 10.0 # 5-10 works fine\n",
    "    return np.stack(image_list), z_spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/membrane/test/22_predict.png\n",
      "Image stack shape: (5, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "image_stack, z_spacing = synth_slice_stack()\n",
    "\n",
    "# Print the shape of the image stack\n",
    "print(\"Image stack shape:\", image_stack.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voxels -> vertices + faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the voxels of interest to a list of faces defined by vertices on the surface of the volume\n",
    "verts, faces, _, _ = skimage.measure.marching_cubes(image_stack, \n",
    "                                                               level=None, \n",
    "                                                               spacing=(z_spacing, 1.0, 1.0),\n",
    "                                                               gradient_direction='descent', \n",
    "                                                               step_size=1, \n",
    "                                                               allow_degenerate=True, \n",
    "                                                               method='lewiner', \n",
    "                                                               mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes verts=(46300, 3) faces=(73768, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of faceted data of the volume discovered by marching_cubes()\n",
    "print(\"shapes verts={0} faces={1}\".format(verts.shape, faces.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertices + faces -> 3D (stl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an stl.Mesh object from the list of faces and vertices\n",
    "cube = Mesh(np.zeros(faces.shape[0], dtype=Mesh.dtype))\n",
    "for i,f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        cube.vectors[i][j] = verts[f[j],:]\n",
    "\n",
    "# Save the mesh file\n",
    "if not os.path.exists(stl_path):\n",
    "    os.makedirs(stl_path)\n",
    "cube.save(stl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
