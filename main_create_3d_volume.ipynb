{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "  [*Ronneberger et al, 2015, U-Net: Convolutional Networks for Biomedical Image Segmentation*](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
    "  \n",
    "  [*Machireddy et al, 2021, Robust Segmentation of Cellular Ultrastructure on Sparsely Labeled 3D Electron Microscopy Images using Deep Learning*](https://www.biorxiv.org/content/10.1101/2021.05.27.446019v1.full)\n",
    "\n",
    "# objectives\n",
    "- PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT PROOF OF CONCEPT \n",
    "- Streamline the use of volumetric electron microscopy (vEM) cell images to create a 3D model for the purpose of gaining *\"deeper understanding of the cellular and subcellular organization of tumor cells and their interactions with the tumor microenvironment (to) shed light on how cancer evolves and guide effective therapy choices.\"*\n",
    "- Provide models and tools for researchers to tailor to meet their needs\n",
    "- Support an interative training and test model, allowing researchers to start/stop and adjust without losing existing progress\n",
    "- Take advantage of hardware acceleration\n",
    "\n",
    "# workflow\n",
    "\n",
    "Using electron microscopy (vEM) cell images to create a 3D model is as follows:\n",
    "- Take a stack of vEM slices of tissue and \n",
    "  - pre-process the images as needed and scale them to 512x512\n",
    "- If training the model\n",
    "  - optionally apply data augmentation to increase the training dataset and push the images through the the training process\n",
    "  - optionally, load a pretrained model and use additional training to fine-tune\n",
    "  - train the model, saving checkpoints periodically and reporting progress as the model is training\n",
    "  - save the final model parameters/weights\n",
    "- If segmenting images with an existing model\n",
    "  - create the model and load pretrained weights into the model\n",
    "  - convert each image into a segmented image using a pretrained UNet model\n",
    "  - save the segmented images as PNG files\n",
    "- Load the stack of images as a 3D [NumPy](https://numpy.org/doc/stable/) array using [imageio.imread()](https://imageio.readthedocs.io/en/v2.16.1/_autosummary/imageio.imread.html).\n",
    "- Use the [marching cubes algorithm](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.marching_cubes) from the scikit-image submodule `skimage.measure` to convert the voxels of interest to a list of faces defined by vertices on the surface of the volume.\n",
    "- Use [numpy-stl](https://numpy-stl.readthedocs.io/en/latest/) to create an `stl.Mesh` object from the list of faces and vertices (as done in [this example](https://numpy-stl.readthedocs.io/en/latest/usage.html#creating-mesh-objects-from-a-list-of-vertices-and-faces)) then save the mesh with `stl.Mesh.save()`.\n",
    "- As a bonus, you can use the Python package for the [Open3D](http://www.open3d.org/docs/release/) library to open & view multiple STL files (not included here)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies\n",
    "\n",
    "model and data use TensorFlow+Keras >= 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from stl import Mesh\n",
    "import skimage.measure\n",
    "import os\n",
    "import glob\n",
    "import random as rand\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knobs and levers\n",
    "\n",
    "edit to match your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of training and test data\n",
    "data_dir = \"data/membrane/\"\n",
    "data_train_dir = data_dir+\"train\"\n",
    "data_test_dir = data_dir+\"test\"\n",
    "\n",
    "# save/load model weights\n",
    "model_weights_file = 'unet_membrane.hdf5'\n",
    "\n",
    "# slice stack sythesizer randomly grabs one image from this match in data_test_dir\n",
    "synth_image_stack_wildcard = \"??_predict.png\"\n",
    "\n",
    "# directory and file name for eventual 3d model\n",
    "stl_path = data_dir+\"3d/\"\n",
    "stl_file = stl_path+\"cube.stl\"\n",
    "\n",
    "# verbose?\n",
    "chatty_mode = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "### train new model\n",
    "\n",
    "TAKES MANY HOURS - SKIP IF USING PRETRAINED MODEL!\n",
    "\n",
    "augments training data, creates the zeroed model, and trains it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model():\n",
    "    data_gen_args = dict(rotation_range=0.2,\n",
    "                        width_shift_range=0.05,\n",
    "                        height_shift_range=0.05,\n",
    "                        shear_range=0.05,\n",
    "                        zoom_range=0.05,\n",
    "                        horizontal_flip=True,\n",
    "                        fill_mode='nearest')\n",
    "\n",
    "    # Load training data generator\n",
    "    train_data_gen = trainGenerator(\n",
    "        2, data_train_dir, 'image', 'label', data_gen_args, save_to_dir=None)\n",
    "\n",
    "    # Build the UNet model\n",
    "    model = unet_model(print_summary=chatty_mode)\n",
    "\n",
    "    # Fit the model using the training data generator - will save checkpoints\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        model_weights_file, monitor='loss', verbose=1 if chatty_mode else 0, save_best_only=True)\n",
    "    model.fit(train_data_gen, steps_per_epoch=2000,\n",
    "            epochs=5, callbacks=[model_checkpoint])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model = train_new_model()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre-trained model\n",
    "\n",
    "OPTIONALLY SKIP IF JUST RAN TRAINING PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 256, 256, 64  640         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_24[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64  0          ['conv2d_25[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_26[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 512)  0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 1024  4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_32[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024  0          ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 1024  0           ['dropout_2[0][0]',              \n",
      "                                )                                 'conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_29[0][0]',              \n",
      "                                                                  'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_39[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_6[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_27[0][0]',              \n",
      "                                6)                                'conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_41[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_42[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_25[0][0]',              \n",
      "                                8)                                'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_44[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,685\n",
      "Trainable params: 31,031,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet_model(model_weights_file, print_summary=chatty_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model and save segmented results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcs\\AppData\\Local\\Temp\\ipykernel_16404\\2878309051.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  results = model.predict_generator(testGene,30,verbose=1 if chatty_mode else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 211ms/step\n"
     ]
    }
   ],
   "source": [
    "# assumes test images are in given directory and have file names <prefix>0.png, <prefix>1.png, ...\n",
    "testGene = testGenerator(data_test_dir)\n",
    "results = model.predict_generator(testGene,30,verbose=1 if chatty_mode else 0)\n",
    "\n",
    "# saves segmented images to  directory with \"_predict\" appeneded i.e. 0_predict.png, ...\n",
    "saveResult(data_test_dir,results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D model\n",
    "\n",
    "### PNGs -> numpy voxel\n",
    "\n",
    "stack segmented images into 3D numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_slice_stack(dup_count=5, print_summary=False):\n",
    "    \n",
    "    # randomly select a segmented image\n",
    "    matching_files = glob.glob(os.path.join(data_test_dir, synth_image_stack_wildcard))\n",
    "    assert len(matching_files) != 0, data_test_dir+synth_image_stack_wildcard+\": found no files\"\n",
    "\n",
    "    z_spacing = 10.0  # 5-10 works fine\n",
    "\n",
    "    print (matching_files)\n",
    "    image_list = []\n",
    "    for file in matching_files:\n",
    "        image_list.append(imageio.v2.imread(file))\n",
    "    image_stack = np.stack(image_list)\n",
    "    return image_stack, z_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/membrane/test\\\\10_predict.png', 'data/membrane/test\\\\11_predict.png', 'data/membrane/test\\\\12_predict.png', 'data/membrane/test\\\\13_predict.png', 'data/membrane/test\\\\14_predict.png', 'data/membrane/test\\\\15_predict.png', 'data/membrane/test\\\\16_predict.png', 'data/membrane/test\\\\17_predict.png', 'data/membrane/test\\\\18_predict.png', 'data/membrane/test\\\\19_predict.png', 'data/membrane/test\\\\20_predict.png', 'data/membrane/test\\\\21_predict.png', 'data/membrane/test\\\\22_predict.png', 'data/membrane/test\\\\23_predict.png', 'data/membrane/test\\\\24_predict.png', 'data/membrane/test\\\\25_predict.png', 'data/membrane/test\\\\26_predict.png', 'data/membrane/test\\\\27_predict.png', 'data/membrane/test\\\\28_predict.png', 'data/membrane/test\\\\29_predict.png']\n"
     ]
    }
   ],
   "source": [
    "image_stack, z_spacing = synth_slice_stack(print_summary=chatty_mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voxels -> vertices + faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the voxels of interest to a list of faces defined by vertices on the surface of the volume\n",
    "verts, faces, _, _ = skimage.measure.marching_cubes(image_stack, \n",
    "                                                               level=None, \n",
    "                                                               spacing=(z_spacing, 1.0, 1.0),\n",
    "                                                               gradient_direction='descent', \n",
    "                                                               step_size=1, \n",
    "                                                               allow_degenerate=True, \n",
    "                                                               method='lewiner', \n",
    "                                                               mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice stack verts=(527170, 3) faces=(1037588, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of faceted data of the volume discovered by marching_cubes()\n",
    "print(\"Slice stack verts={0} faces={1}\".format(verts.shape, faces.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertices + faces -> 3D mesh -> STL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D model generated to data/membrane/3d/cube.stl\n"
     ]
    }
   ],
   "source": [
    "# create an stl.Mesh object from the list of faces and vertices\n",
    "cube = Mesh(np.zeros(faces.shape[0], dtype=Mesh.dtype))\n",
    "for i,f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        cube.vectors[i][j] = verts[f[j],:]\n",
    "\n",
    "# Save mesh as STL file that can be natively viewed on MacOS, Windows, Linux and can be easily 3D printed\n",
    "if not os.path.exists(stl_path):\n",
    "    os.makedirs(stl_path)\n",
    "cube.save(stl_file)\n",
    "print(\"3D model generated to {0}\".format(stl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
